{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31fb71e",
   "metadata": {},
   "source": [
    "### Extracting ZIP File and Removing Unwanted Files (Only Keeping .csv and .xls)\n",
    " \n",
    "\n",
    "1.Extracts all contents from the ZIP file named \"LinkedIn Data Public.zip\" into a folder called \"extracted_data\".\n",
    "\n",
    "2.Walks through the extracted folder and deletes all files that are not .csv or .xls.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f6e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = 'LinkedIn Data Public.zip'\n",
    "extract_path = 'extracted_data'\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "\n",
    "allowed_extensions = ['.csv', '.xls']\n",
    "\n",
    "for root, dirs, files in os.walk(extract_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if not any(file.lower().endswith(ext) for ext in allowed_extensions):\n",
    "            os.remove(file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63099f44",
   "metadata": {},
   "source": [
    "### Converting `.xls` Files to `.csv` in a Folder and Deleting the Original Files\n",
    "\n",
    "1. Walks through the `extracted_data` folder and checks for files ending with `.xls`.\n",
    "\n",
    "2. Converts each `.xls` file to `.csv` using pandas.\n",
    "\n",
    "3. Saves the new `.csv` file in the same location with the same base name.\n",
    "\n",
    "4. Deletes the original `.xls` file after conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = 'extracted_data'  # the folder where the files are stored\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        # if the file is .xls, convert it to .csv\n",
    "        if file.lower().endswith('.xls'):\n",
    "            df = pd.read_excel(file_path)  # read the Excel (.xls) file\n",
    "            new_file = file.rsplit('.', 1)[0] + '.csv'  # replace .xls with .csv in filename\n",
    "            new_file_path = os.path.join(root, new_file)\n",
    "            df.to_csv(new_file_path, index=False)  # save the data as a .csv file\n",
    "            os.remove(file_path)  # delete the original .xls file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696764f1",
   "metadata": {},
   "source": [
    "### Renaming `.csv` Files to Lowercase in a Folder\n",
    "\n",
    "1. Walks through the `extracted_data` folder and checks for all `.csv` files.\n",
    "\n",
    "2. Converts each filename to lowercase if it’s not already.\n",
    "\n",
    "3. Renames the file in place using the new lowercase name.\n",
    "\n",
    "4. Prints a confirmation message once all renaming is done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af8f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All .csv file names have been converted to lowercase!\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# # Folder path jahan tumhari .csv files hain\n",
    "# folder_path = 'extracted_data'\n",
    "import os\n",
    "\n",
    "# Folder path where your .csv files are located\n",
    "folder_path = 'extracted_data'\n",
    "\n",
    "# Loop through the folder and rename .csv files to lowercase\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            old_path = os.path.join(root, file)\n",
    "            new_filename = file.lower()\n",
    "            new_path = os.path.join(root, new_filename)\n",
    "\n",
    "            # Rename the file only if it's not already in lowercase\n",
    "            if file != new_filename:\n",
    "                os.rename(old_path, new_path)\n",
    "\n",
    "print(\" All .csv file names have been converted to lowercase!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3f569",
   "metadata": {},
   "source": [
    "### Cleaning and Renaming `.csv` Files to Ensure Uniqueness and Remove Duplicates\n",
    "\n",
    "1. Walks through the `extracted_data` folder and looks for `.csv` files.\n",
    "\n",
    "2. Cleans the file names by removing the word \"connection\" and non-alphabetic characters, converting everything to lowercase.\n",
    "\n",
    "3. Ensures that if a file name contains repeated words (e.g., 'pragatichauhanpragatichauhan'), it is simplified to a single occurrence of the word.\n",
    "\n",
    "4. Checks for uniqueness of the cleaned filename. If a file with the same name already exists, it appends a number (e.g., `name_1.csv`, `name_2.csv`) until the filename is unique.\n",
    "\n",
    "5. Renames the file and stores the new filename in the `used_names` set to avoid duplicates.\n",
    "\n",
    "6. Prints a confirmation message once all files are renamed safely without overwriting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb546f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files cleaned safely without overwriting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "folder_path = 'extracted_data'  # Path to the folder containing the .csv files\n",
    "used_names = set()  # Set to keep track of used filenames for uniqueness\n",
    "\n",
    "# Function to clean up filenames\n",
    "def clean_name(name):\n",
    "    name = name.replace('connection', '')  # Remove the word 'connection'\n",
    "    name = re.sub(r'[^a-z]', '', name.lower())  # Remove non-alphabet characters and convert to lowercase\n",
    "\n",
    "    # Remove duplicated full words (e.g., 'pragatichauhanpragatichauhan' becomes 'pragatichauhan')\n",
    "    for i in range(1, len(name)//2 + 1):\n",
    "        first = name[:i]\n",
    "        if name == first * (len(name)//len(first)):\n",
    "            return first  # Return the first occurrence of the repeated word\n",
    "    return name  # Return cleaned name\n",
    "\n",
    "# Walk through the folder and process each file\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):  # Check if the file is a .csv file\n",
    "            old_path = os.path.join(root, file)  # Get the full path of the old file\n",
    "            name_only = os.path.splitext(file)[0]  # Get the name of the file without extension\n",
    "            cleaned_name = clean_name(name_only)  # Clean the filename\n",
    "\n",
    "            # Ensure uniqueness of the new filename\n",
    "            new_filename = cleaned_name + '.csv'  # Prepare the new filename\n",
    "            count = 1\n",
    "            while new_filename in used_names:  # If filename already exists, append a number\n",
    "                new_filename = f\"{cleaned_name}_{count}.csv\"\n",
    "                count += 1\n",
    "\n",
    "            new_path = os.path.join(root, new_filename)  # Get the full path of the new file\n",
    "            os.rename(old_path, new_path)  # Rename the file\n",
    "            used_names.add(new_filename)  # Add the new filename to the used names set\n",
    "\n",
    "print(\"All files cleaned safely without overwriting.\")  # Confirmation message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e54280",
   "metadata": {},
   "source": [
    "### Cleaning and Saving LinkedIn Data\n",
    "\n",
    "1. **Step 1:** Load the CSV file from the specified path (`aadityaraj.csv`).\n",
    "\n",
    "2. **Step 2:** Define a function `clean_text()` to remove unwanted characters (non-alphanumeric) from the text. It keeps only alphanumeric characters, spaces, and parentheses.\n",
    "\n",
    "3. **Step 3:** Apply the `clean_text()` function to every cell in the dataframe to clean all values.\n",
    "\n",
    "4. **Step 4:** Create a new column `Full Name` by combining the 'First Name' and 'Last Name' columns. If either of the columns is missing, an error message is displayed.\n",
    "\n",
    "5. **Step 5:** Capitalize the values in the `Full Name` and `Company` columns. If the 'Company' column is missing, an error message is displayed.\n",
    "\n",
    "6. **Step 6:** Retain only the `Full Name` and `Company` columns, discarding the rest.\n",
    "\n",
    "7. **Step 7:** Save the cleaned data back to the original CSV file (or to a new file by modifying the path).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dd2e536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data/LinkedIn Data Public/aadityaraj.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praga\\AppData\\Local\\Temp\\ipykernel_15388\\1592355255.py:15: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(clean_text)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "file_path = r'C:/SEMESTER 2/Mfc/extracted_data/LinkedIn Data Public/aadityaraj.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Function to clean the text\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return ''  # Return empty string if the text is NaN\n",
    "    return re.sub(r'[^a-zA-Z0-9() ]+', '', str(text))  # Remove non-alphanumeric characters\n",
    "\n",
    "# Step 3: Apply the clean_text function to every cell in the DataFrame\n",
    "df = df.applymap(clean_text)\n",
    "\n",
    "#  Step 4: Create 'Full Name' column (First Name + Last Name)\n",
    "if 'First Name' in df.columns and 'Last Name' in df.columns:\n",
    "    df['Full Name'] = df['First Name'].str.strip() + ' ' + df['Last Name'].str.strip()  # Combine First and Last Name\n",
    "else:\n",
    "    print(\"First Name' or 'Last Name' column is missing!\")\n",
    "\n",
    "#  Step 5: Capitalize 'Full Name' and 'Company' columns\n",
    "df['Full Name'] = df['Full Name'].str.title()  # Capitalize the 'Full Name'\n",
    "\n",
    "if 'Company' in df.columns:\n",
    "    df['Company'] = df['Company'].str.title()  # Capitalize the 'Company' name\n",
    "else:\n",
    "    print(\"Company' column is missing!\")\n",
    "\n",
    "#  Step 6: Keep only 'Full Name' and 'Company' columns\n",
    "df = df[['Full Name', 'Company']]  # Retain only the relevant columns\n",
    "\n",
    "# Step 7: Save the file (either original or new)\n",
    "output_path = r'C:/SEMESTER 2/Mfc/extracted_data/LinkedIn Data Public/aadityaraj.csv'  # Overwrite the original file\n",
    "# output_path = r'C:/SEMESTER 2/Mfc/extracted_data 1/cleaned_aadityaraj.csv'  # Save as a new file\n",
    "\n",
    "df.to_csv(output_path, index=False)  # Save the cleaned data to a CSV file\n",
    "print(\"File cleaned and saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fbf40d",
   "metadata": {},
   "source": [
    "### Bulk Clean and Format LinkedIn Data (CSV Files)\n",
    "\n",
    "This script processes multiple CSV files inside a folder containing LinkedIn connection data and generates cleaned versions in a separate output folder.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "#### 1. **Text Cleaning**\n",
    "- Removes HTML tags.\n",
    "- Removes URLs.\n",
    "- Removes special characters.\n",
    "- Removes extra spaces.\n",
    "\n",
    "#### 2. **Full Name Formatting**\n",
    "- Combines `First Name` and `Last Name` into a new column called `Full Name`.\n",
    "- Capitalizes the first letter of each word in the full name.\n",
    "- Drops `First Name` and `Last Name` columns after combining.\n",
    "\n",
    "#### 3. **Company Name Cleaning**\n",
    "- Keeps only the `Full Name` and `Company` columns (if present).\n",
    "- Cleans and standardizes both columns.\n",
    "\n",
    "#### 4. **File Handling**\n",
    "- Skips unreadable lines using `on_bad_lines='skip'`.\n",
    "- Automatically detects and handles both `utf-8` and `latin-1` encodings.\n",
    "- Removes any columns with names starting with `\"Unnamed\"` (usually auto-generated).\n",
    "- Drops rows where both `Full Name` and `Company` are blank.\n",
    "\n",
    "#### 5. **File Saving**\n",
    "- Output files are saved in a separate folder called `Cleaned LinkedIn Data`.\n",
    "- The file name is capitalized (first letter only) for standardization.\n",
    "\n",
    "\n",
    "### 📂 Input Folder\n",
    "`C:/SEMESTER 2/Mfc/extracted_data/LinkedIn Data Public`\n",
    "\n",
    "### 📁 Output Folder\n",
    "`C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data`\n",
    "\n",
    "\n",
    "Each cleaned file is saved in the output folder and a confirmation message is printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33cbf2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Aadityaraj.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Abhisheksingh.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Adityasinghadityanolastname.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Afzalrazaafzlraza.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ajayjatavsajayjatav.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ajityadav.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Akankshakushwahaakanksha.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Alokraj.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Amanadarsh.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Amanadarsh_1.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Amansingh.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Amitkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Anamikakumari.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Anandpandey.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Anoopkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Anshukumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Anuradhatiwari.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Anushrimishra.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Aradhyapatel.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Arjunkadam.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Arpitatripathi.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Arunsingharunkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Aryansaini.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ayushkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ayushyadav.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Bhagwatichouhanbhagwatinolastname.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Bhaskarmahato.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Byagaripraveenkumarbyagarikumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Challatrivedhkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Chandangiri.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Chiranjeetbiswas.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Cleanedsbhagwansinghrawat.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Debangsumisracsvdebangsumisra.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Dilipsuthar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Dishasahu.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Divyanshirathour.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Divyanshisahucsvdivyanshisahu.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ektakumari.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Gauravkhainwarcsvgauravkhainwar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Gauravrathore.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Gauravtiwari.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Harisinghrajpoot.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Himanshukanwarchundawathimanshuchundawat.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Himanshukumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Himanshusrivastav.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Hiranyapatil.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ishantbhoyar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Jamalakhtar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Januchaudhary.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Karanpalsinghranawat.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Khushinarwariya.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Kuldeepsaraswat.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Lakhanrathore.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Linkedinlistnidhikumari.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Linkedinsaminasultana.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Linkedinssnehashaw.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Maneeshsakhwar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Manishtiwarimanishkumartiwari.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Mausamkumari.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Mayankraj.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Mehtabalam.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Mohdmonismonis.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Mohitsharma.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Monurajpoot.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Namandamami.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Neerajparmar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Nikhilchaurasiya.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Nirmallinkdinsnirmalmewada.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Pawankushwah.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Pinkyrana.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Pooransingh.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Prabhatpatidar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Prachidhakad.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Pragatichauhan.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Pranjaldubey.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Premkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Preranarajnag.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Priyadarshikumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Priyasaini.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Pushprajsinghcsvpushprajsingh.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Rahulkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Rahulkumarvermarahulverma.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Rajivkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ramrajnagar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ranikumari.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ranjeetkumaryadavranjeetyadav.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ravimourya.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ritiksingh.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Rohitkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Rohitmalviya.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sajankumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Samanverma.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Saminasultana.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sanandsingh.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sandeepkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sandhyakaushal.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sandhyaparmar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sarthaksumanmishrasarthakmishra.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Satishmahto.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sauhardkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Saurabhbisht.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Shahidansari.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sharshitchaturvedi.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Shilpishaw.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Shivamshukla.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Shivangdubey.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Shlokgupta.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Shubhamkang.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Shubhamkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Snarunkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Snehashaw.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sompalyadav.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sravirajput.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Sunnykumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Suyashyadav.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Swatikumari.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Ujjvalbaijal.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Upparasaimaithreyiupparamaithreyi.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Vinaygupta.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Vinaykumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Vishalbhardwaj.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Vishalkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Vivekkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Viveksinghvivekkumar.csv\n",
      "✅ Cleaned and saved: C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data\\Yuvrajsinghbhatiyuvrajbhati.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to clean text data\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    text = str(text)\n",
    "    text = re.sub(r'<[^>]*>', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Function to format full name properly\n",
    "def format_full_name(name):\n",
    "    if pd.isnull(name) or str(name).strip() == '':\n",
    "        return ''\n",
    "    return ' '.join(word.capitalize() for word in str(name).split())\n",
    "\n",
    "# Input and output folders\n",
    "input_folder = r'C:/SEMESTER 2/Mfc/extracted_data/LinkedIn Data Public'\n",
    "output_folder = r'C:/SEMESTER 2/Mfc/extracted_data 1/Cleaned LinkedIn Data'\n",
    "\n",
    "# Create output folder if not exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get list of CSV files in input folder\n",
    "csv_files = [file for file in os.listdir(input_folder) if file.endswith('.csv')]\n",
    "\n",
    "# Loop through all files\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(file_path, encoding='latin-1', on_bad_lines='skip')\n",
    "\n",
    "    # Remove unnamed columns\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    # Clean object columns\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].map(clean_text)\n",
    "\n",
    "    # Combine first and last name\n",
    "    if 'First Name' in df.columns and 'Last Name' in df.columns:\n",
    "        df['Full Name'] = (df['First Name'].fillna('') + ' ' + df['Last Name'].fillna('')).str.strip()\n",
    "        df.drop(columns=['First Name', 'Last Name'], inplace=True)\n",
    "    elif 'Full Name' not in df.columns:\n",
    "        df['Full Name'] = ''\n",
    "\n",
    "    # Format full name\n",
    "    df['Full Name'] = df['Full Name'].map(format_full_name)\n",
    "\n",
    "    # Keep only Full Name and Company\n",
    "    keep_columns = ['Full Name', 'Company']\n",
    "    df = df[[col for col in keep_columns if col in df.columns]]\n",
    "\n",
    "    # Drop completely blank rows\n",
    "    full_name_col = df['Full Name'] if 'Full Name' in df.columns else pd.Series('', index=df.index)\n",
    "    company_col = df['Company'] if 'Company' in df.columns else pd.Series('', index=df.index)\n",
    "\n",
    "    df = df[~((full_name_col.fillna('').str.strip() == '') & (company_col.fillna('').str.strip() == ''))]\n",
    "\n",
    "    # Capitalize only the first letter of file name\n",
    "    final_filename = file[0].upper() + file[1:] if len(file) > 1 else file.upper()\n",
    "    cleaned_file_path = os.path.join(output_folder, final_filename)\n",
    "\n",
    "    # Save the final cleaned file\n",
    "    df.to_csv(cleaned_file_path, index=False)\n",
    "    print(f\"✅ Cleaned and saved: {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267e64d8",
   "metadata": {},
   "source": [
    "### 🧹 Manual Cleaning Notes\n",
    "\n",
    "-  Renamed a few files manually to avoid name repetition.\n",
    "-  Cleaned some files separately due to missing data.\n",
    "- Example: Created the **Company** column manually in *Pooran Singh*'s file using Excel.\n",
    "-  Fixed encoding issues in specific files like *Manoj Dewada* and *Monoj Kharkhar* by converting text to **UTF-8**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f13c4ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
